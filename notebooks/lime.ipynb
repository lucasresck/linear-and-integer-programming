{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surprising-values",
   "metadata": {},
   "source": [
    "# Mixed-Integer Linear Programming (MILP) for Local Interpretable Model-agnostic Explanations (LIME)\n",
    "\n",
    "This study aims to formulate (and test) Local Interpretable Model-agnostic Explanations (LIME) using Mixed-Integer Linear Programming (MILP).\n",
    "\n",
    "- Lucas Emanuel Resck Domingues\n",
    "- Professor: Luciano Guimar√£es\n",
    "- FGV-EMAp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-efficiency",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The Optimization field is today one of the most important fields of Applied Mathematics.\n",
    "Not only the theory and the research are very solid, but also the applications are everywhere, from Engineering to Management. In general, problems of this kind try to deal with the maximization or minimization of a function, given some conditions in the variables.\n",
    "\n",
    "The main problem of Machine Learning, on the other hand, is to search for a function that represents the observed phenomenon using observed data. In fact, it can also be seen as an optimization problem, where the optimal function (given the data) is sought. For example, the goal of training a deep neural network is to search for a local mininum (with luck, a global mininum) for the loss function, given the data.\n",
    "\n",
    "Machine Learning models have a problem: many of them are not interpretable. Some of them are so incognito that they are called \"black-box\", in reference to airplane's black-box.\n",
    "This way, many researchers presented methods of explaining and interpreting Machine Learning model results.\n",
    "One of them is Local Interpretable Model-agnostic Explanations (LIME), the focus of this study.\n",
    "\n",
    "Suppose you have a text classification model (each text is assigned to a class) that says you if a text is mathematical or not. You want to understand why the model says this Introduction text (we call it $x$) is mathematical. LIME disturbs the text $x$ and verify the changes in probabilities $f(x)$. It tries to fit a simpler (but interpretable) model $g$, trying to predict the probabilities $f(x)$ over the pertubations of the input $x$. Mathematically, LIME tries to search for\n",
    "\n",
    "$$\\xi(x) = \\mathrm{argmin}_{g \\in G} \\mathcal{L}(f, g, \\pi_x) + \\Omega(g),$$\n",
    "\n",
    "being $G$ the set of desired interpretable functions, $\\pi_x$ the locallity around $x$, $\\mathcal{L}$ some measure of non proximity between $f, g$ in the locallity given by $\\pi_x$, and $\\Omega(g)$ being the complexity of $g$.\n",
    "Very abstract, but it will be more clear in the following sections.\n",
    "\n",
    "In general, LIME formulation is not MILP, but we can addapt the formulation to have it MILP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-leone",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Only Python and Jupyter stuff. You can jump over this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from pulp import LpVariable, LpProblem, value, LpStatus, LpMinimize\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-cross",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-teaching",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/IMDB Dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    '''Preprocess text.'''\n",
    "    return text.replace('<br />', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review = df.review.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.review.to_list()\n",
    "y = df.sentiment.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-google",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(\n",
    "    strip_accents=None,\n",
    "    lowercase=True,\n",
    "    smooth_idf=True,\n",
    ")\n",
    "X_train = tf_idf.fit_transform(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "X_train = t_svd.fit_transform(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LinearSVC(\n",
    "    dual=False,  # n_samples > n_features\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svm = GridSearchCV(\n",
    "    estimator,\n",
    "    param_grid={'C': np.logspace(-2, 10, 13)},\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svm = CalibratedClassifierCV(svm.best_estimator_, cv=5)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = Pipeline([\n",
    "    ('tf_idf', tf_idf),\n",
    "    ('t_svd', t_svd)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('tf_idf', tf_idf),\n",
    "    ('t_svd', t_svd),\n",
    "    ('scaler', scaler),\n",
    "    ('svm', svm)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-purse",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-design",
   "metadata": {},
   "source": [
    "### LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-failure",
   "metadata": {},
   "source": [
    "### Calculation of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(text):\n",
    "    '''Probability of a text'''\n",
    "    return model.predict_proba([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi(x, z, sigma_2=-1/np.log(0.1)):\n",
    "    '''Weights of locallity.'''\n",
    "    x = vector.transform([x])[0]\n",
    "    z = vector.transform([z])[0]\n",
    "    # If null vector\n",
    "    if np.abs(z).sum() == 0:\n",
    "        return 0\n",
    "    # Cosine of angle between vectors\n",
    "    cos = np.dot(x, z)/(np.linalg.norm(x)*np.linalg.norm(z))\n",
    "    # If cosine is like 1.00008\n",
    "    if cos > 1:\n",
    "        cos = 1\n",
    "    # Angle between vectors, normalized to between 0 and 1\n",
    "    D = np.arccos(cos)*2/np.pi\n",
    "    return np.exp(-D**2/sigma_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters(split, which_class, M, N, K):\n",
    "    '''Return the parameters for LIME optimization.'''\n",
    "    # Perturbations\n",
    "    z_line = []\n",
    "    # Probabilities\n",
    "    f_z = []\n",
    "    # Weights\n",
    "    pi_x = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Choose a random number of words to remove, between 1 and (split - 1)\n",
    "        n = np.random.choice(range(1, M))\n",
    "        # Remove n random words\n",
    "        indices = np.random.choice(range(M), size=n, replace=False)\n",
    "        \n",
    "        # The pertubartion\n",
    "        perturbation = np.ones(M)\n",
    "        for index in indices:\n",
    "            perturbation[index] = 0\n",
    "        z_line.append(perturbation)\n",
    "            \n",
    "        # The probability and weight\n",
    "        text = ' '.join([word for (j, word) in enumerate(split) if perturbation[j]])\n",
    "        f_z.append(f(text)[which_class])\n",
    "        pi_x.append(pi(example, text))\n",
    "    \n",
    "    return z_line, f_z, pi_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-transcription",
   "metadata": {},
   "source": [
    "### Linear optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization(z_line, f_z, pi_x, M, N, K, lambda_=0.5):\n",
    "    '''The MILP for LIME.'''\n",
    "    prob = LpProblem(\"LIME\", LpMinimize)\n",
    "    \n",
    "    # Variables\n",
    "    L = LpVariable('L')\n",
    "    Omega = LpVariable('Omega')\n",
    "    epsilon = [LpVariable('epsilon_{}'.format(i)) for i in range(N)]\n",
    "    delta = [LpVariable('delta_{}'.format(i)) for i in range(M)]\n",
    "    g = [LpVariable(\"g(z'_{})\".format(i)) for i in range(N)]\n",
    "    x = [LpVariable('x_{}'.format(j)) for j in range(M)]\n",
    "#     y = [LpVariable('y_{}'.format(j), 0, 1, cat='Integer') for j in range(M)]\n",
    "    \n",
    "    # Objective\n",
    "    prob += L + lambda_*Omega\n",
    "    \n",
    "    # Constraints\n",
    "    prob += L == sum([pi_x[i]*epsilon[i] for i in range(N)])\n",
    "    prob += Omega == sum(delta)\n",
    "\n",
    "    for i in range(N):\n",
    "        prob += -epsilon[i] <= f_z[i] - g[i]\n",
    "        prob += epsilon[i] >= f_z[i] - g[i]\n",
    "        prob += g[i] == sum([z_line[i][j]*x[j] for j in range(M)])\n",
    "\n",
    "    infinity = 100000\n",
    "    for j in range(M):\n",
    "        prob += -delta[j] <= x[j]\n",
    "        prob += delta[j] >= x[j]\n",
    "        \n",
    "#         prob += -infinity*y[j] <= x[j]\n",
    "#         prob += infinity*y[j] >= x[j]\n",
    "\n",
    "#     prob += sum(y) <= K\n",
    "\n",
    "    print('Solving MILP...')\n",
    "    status = prob.solve()\n",
    "    print('Done.')\n",
    "    \n",
    "    return prob, status, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(split, importances):\n",
    "    '''Visualize the importance of each word in the classification.'''\n",
    "    max_abs_importance = np.max(np.abs(importances))\n",
    "    # Green\n",
    "    positive = np.array([0, 255, 0])\n",
    "    white = np.array([255, 255, 255])\n",
    "    # Red\n",
    "    negative = np.array([255, 0, 0])\n",
    "    spans = []\n",
    "    for i, word in enumerate(split):\n",
    "        if importances[i] >= 0:\n",
    "            color = white + (positive - white)/max_abs_importance*importances[i]\n",
    "        else:\n",
    "            color = white + (negative - white)/((-1)*max_abs_importance)*importances[i]\n",
    "        spans.append(\n",
    "            '<span style=\"background-color: RGB({R}, {G}, {B})\">{word}</span>'.format(\n",
    "                word=word,\n",
    "                R=color[0],\n",
    "                G=color[1],\n",
    "                B=color[2]\n",
    "            )\n",
    "        )\n",
    "            \n",
    "    html = ' '.join(spans)\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lime(text, which_class, N=None, K=None):\n",
    "    # Split \n",
    "    split = text.split()\n",
    "    M = len(split)\n",
    "    if N is None:\n",
    "        N = 5*M\n",
    "#     if K is None:\n",
    "#         K = min([M, 20])\n",
    "                \n",
    "    z_line, f_z, pi_x = parameters(split, which_class, M, N, K)\n",
    "        \n",
    "    prob, status, x = optimization(z_line, f_z, pi_x, M, N, K)\n",
    "    \n",
    "    importances = [value(i) for i in x]    \n",
    "    print(dict(zip(split, importances)))    \n",
    "    \n",
    "    return visualize(split, importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-trustee",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = 'This movie is awful, I regret seing it, it is a bad movie.'\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba([example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime(example, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-provider",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://arxiv.org/pdf/1602.04938.pdf\n",
    "- https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "- https://vanderbei.princeton.edu/tex/talks/MOPTA14/L1_reg.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
