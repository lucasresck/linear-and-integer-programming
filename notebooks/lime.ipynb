{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surprising-values",
   "metadata": {},
   "source": [
    "# Mixed-Integer Linear Programming (MILP) for Local Interpretable Model-agnostic Explanations (LIME)\n",
    "\n",
    "This study aims to formulate (and test) Local Interpretable Model-agnostic Explanations (LIME) using Mixed-Integer Linear Programming (MILP).\n",
    "\n",
    "- Lucas Emanuel Resck Domingues\n",
    "- Professor: Luciano Guimarães\n",
    "- FGV-EMAp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-prior",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Data</a></span></li><li><span><a href=\"#Classifier\" data-toc-modified-id=\"Classifier-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Classifier</a></span></li></ul></li><li><span><a href=\"#Optimization\" data-toc-modified-id=\"Optimization-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Optimization</a></span><ul class=\"toc-item\"><li><span><a href=\"#LIME\" data-toc-modified-id=\"LIME-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>LIME</a></span></li><li><span><a href=\"#Calculation-of-parameters\" data-toc-modified-id=\"Calculation-of-parameters-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Calculation of parameters</a></span></li><li><span><a href=\"#Linear-optimization\" data-toc-modified-id=\"Linear-optimization-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Linear optimization</a></span></li><li><span><a href=\"#Examples\" data-toc-modified-id=\"Examples-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Examples</a></span></li></ul></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-efficiency",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The Optimization field is today one of the most important fields of Applied Mathematics.\n",
    "Not only the theory and the research are very solid, but also the applications are everywhere, from Engineering to Management. In general, problems of this kind try to deal with the maximization of minimization of a function given some conditions to the variables.\n",
    "\n",
    "The main problem of Machine Learning is to search for a function that represents the observed phenomenon Many machine learning problems can be understood as optimization problems. \n",
    "\n",
    "- Machine learning\n",
    "- Machine learning com otimização\n",
    "- O problema da caixa preta\n",
    "\n",
    "- Modelos de interpretação\n",
    "- LIME\n",
    "- LIME como otimização\n",
    "- Não é linear, mas dá pra tentar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-leone",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Only Python and Jupyter stuff. You can jump over this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "preliminary-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from pulp import LpVariable, LpProblem, value, LpStatus, LpMinimize\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "secondary-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-cross",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-teaching",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "known-pledge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/IMDB Dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "heated-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    '''Preprocess text.'''\n",
    "    return text.replace('<br />', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "congressional-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review = df.review.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "binary-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.review.to_list()\n",
    "y = df.sentiment.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "spatial-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-google",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "veterinary-injection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 94342)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer(\n",
    "    strip_accents=None,\n",
    "    lowercase=True,\n",
    "    smooth_idf=True,\n",
    ")\n",
    "X_train = tf_idf.fit_transform(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "damaged-history",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 50)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "X_train = t_svd.fit_transform(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "quantitative-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "unlimited-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LinearSVC(\n",
    "    dual=False,  # n_samples > n_features\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svm = GridSearchCV(\n",
    "    estimator,\n",
    "    param_grid={'C': np.logspace(-2, 10, 13)},\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "rubber-poetry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "[LibLinear]CPU times: user 644 ms, sys: 152 ms, total: 796 ms\n",
      "Wall time: 5.65 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(dual=False, random_state=42, verbose=1),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05,\n",
       "       1.e+06, 1.e+07, 1.e+08, 1.e+09, 1.e+10])},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bottom-singer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]CPU times: user 3.12 s, sys: 2.35 s, total: 5.47 s\n",
      "Wall time: 1.19 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LinearSVC(C=0.1, dual=False,\n",
       "                                                random_state=42, verbose=1),\n",
       "                       cv=5)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm = CalibratedClassifierCV(svm.best_estimator_, cv=5)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "least-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = Pipeline([\n",
    "    ('tf_idf', tf_idf),\n",
    "    ('t_svd', t_svd)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "aging-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('tf_idf', tf_idf),\n",
    "    ('t_svd', t_svd),\n",
    "    ('scaler', scaler),\n",
    "    ('svm', svm)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "demonstrated-dominican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8427"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-purse",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-design",
   "metadata": {},
   "source": [
    "### LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-failure",
   "metadata": {},
   "source": [
    "### Calculation of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "paperback-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(text):\n",
    "    '''Probability of a text'''\n",
    "    return model.predict_proba([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "biblical-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi(x, z, sigma_2=-1/np.log(0.1)):\n",
    "    '''Weights of locallity.'''\n",
    "    x = vector.transform([x])[0]\n",
    "    z = vector.transform([z])[0]\n",
    "    # If null vector\n",
    "    if np.abs(z).sum() == 0:\n",
    "        return 0\n",
    "    # Cosine of angle between vectors\n",
    "    cos = np.dot(x, z)/(np.linalg.norm(x)*np.linalg.norm(z))\n",
    "    # If cosine is like 1.00008\n",
    "    if cos > 1:\n",
    "        cos = 1\n",
    "    # Angle between vectors, normalized to between 0 and 1\n",
    "    D = np.arccos(cos)*2/np.pi\n",
    "    return np.exp(-D**2/sigma_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "strong-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters(split, which_class, M, N, K):\n",
    "    '''Return the parameters for LIME optimization.'''\n",
    "    # Perturbations\n",
    "    z_line = []\n",
    "    # Probabilities\n",
    "    f_z = []\n",
    "    # Weights\n",
    "    pi_x = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Choose a random number of words to remove, between 1 and (split - 1)\n",
    "        n = np.random.choice(range(1, M))\n",
    "        # Remove n random words\n",
    "        indices = np.random.choice(range(M), size=n, replace=False)\n",
    "        \n",
    "        # The pertubartion\n",
    "        perturbation = np.ones(M)\n",
    "        for index in indices:\n",
    "            perturbation[index] = 0\n",
    "        z_line.append(perturbation)\n",
    "            \n",
    "        # The probability and weight\n",
    "        text = ' '.join([word for (j, word) in enumerate(split) if perturbation[j]])\n",
    "        f_z.append(f(text)[which_class])\n",
    "        pi_x.append(pi(example, text))\n",
    "    \n",
    "    return z_line, f_z, pi_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-transcription",
   "metadata": {},
   "source": [
    "### Linear optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "stretch-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization(z_line, f_z, pi_x, M, N, K, lambda_=0.5):\n",
    "    '''The MILP for LIME.'''\n",
    "    prob = LpProblem(\"LIME\", LpMinimize)\n",
    "    \n",
    "    # Variables\n",
    "    L = LpVariable('L')\n",
    "    Omega = LpVariable('Omega')\n",
    "    epsilon = [LpVariable('epsilon_{}'.format(i)) for i in range(N)]\n",
    "    delta = [LpVariable('delta_{}'.format(i)) for i in range(M)]\n",
    "    g = [LpVariable(\"g(z'_{})\".format(i)) for i in range(N)]\n",
    "    x = [LpVariable('x_{}'.format(j)) for j in range(M)]\n",
    "#     y = [LpVariable('y_{}'.format(j), 0, 1, cat='Integer') for j in range(M)]\n",
    "    \n",
    "    # Objective\n",
    "    prob += L + lambda_*Omega\n",
    "    \n",
    "    # Constraints\n",
    "    prob += L == sum([pi_x[i]*epsilon[i] for i in range(N)])\n",
    "    prob += Omega == sum(delta)\n",
    "\n",
    "    for i in range(N):\n",
    "        prob += -epsilon[i] <= f_z[i] - g[i]\n",
    "        prob += epsilon[i] >= f_z[i] - g[i]\n",
    "        prob += g[i] == sum([z_line[i][j]*x[j] for j in range(M)])\n",
    "\n",
    "    infinity = 100000\n",
    "    for j in range(M):\n",
    "        prob += -delta[j] <= x[j]\n",
    "        prob += delta[j] >= x[j]\n",
    "        \n",
    "#         prob += -infinity*y[j] <= x[j]\n",
    "#         prob += infinity*y[j] >= x[j]\n",
    "\n",
    "#     prob += sum(y) <= K\n",
    "\n",
    "    print('Solving MILP...')\n",
    "    status = prob.solve()\n",
    "    print('Done.')\n",
    "    \n",
    "    return prob, status, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "opened-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(split, importances):\n",
    "    '''Visualize the importance of each word in the classification.'''\n",
    "    max_abs_importance = np.max(np.abs(importances))\n",
    "    # Green\n",
    "    positive = np.array([0, 255, 0])\n",
    "    white = np.array([255, 255, 255])\n",
    "    # Red\n",
    "    negative = np.array([255, 0, 0])\n",
    "    spans = []\n",
    "    for i, word in enumerate(split):\n",
    "        if importances[i] >= 0:\n",
    "            color = white + (positive - white)/max_abs_importance*importances[i]\n",
    "        else:\n",
    "            color = white + (negative - white)/((-1)*max_abs_importance)*importances[i]\n",
    "        spans.append(\n",
    "            '<span style=\"background-color: RGB({R}, {G}, {B})\">{word}</span>'.format(\n",
    "                word=word,\n",
    "                R=color[0],\n",
    "                G=color[1],\n",
    "                B=color[2]\n",
    "            )\n",
    "        )\n",
    "            \n",
    "    html = ' '.join(spans)\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "funded-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lime(text, which_class, N=None, K=None):\n",
    "    # Split \n",
    "    split = text.split()\n",
    "    M = len(split)\n",
    "    if N is None:\n",
    "        N = 5*M\n",
    "#     if K is None:\n",
    "#         K = min([M, 20])\n",
    "                \n",
    "    z_line, f_z, pi_x = parameters(split, which_class, M, N, K)\n",
    "        \n",
    "    prob, status, x = optimization(z_line, f_z, pi_x, M, N, K)\n",
    "    \n",
    "    importances = [value(i) for i in x]    \n",
    "    print(dict(zip(split, importances)))    \n",
    "    \n",
    "    return visualize(split, importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-trustee",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "signed-queensland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This movie is awful, I regret seing it, it is a bad movie.'"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 'This movie is awful, I regret seing it, it is a bad movie.'\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "careful-equipment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype='<U8')"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "female-piano",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99280004, 0.00719996]])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba([example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "special-onion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving MILP...\n",
      "Done.\n",
      "{'This': 0.0, 'movie': 0.013286572, 'is': 0.10326589, 'awful,': 0.14443269, 'I': 0.039677759, 'regret': 0.037821996, 'seing': 0.1615384, 'it,': 0.044888046, 'it': 0.079345289, 'a': 0.05742599, 'bad': 0.37240251, 'movie.': 0.12055832}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: RGB(255.0, 255.0, 255.0)\">This</span> <span style=\"background-color: RGB(245.90211325374793, 255.0, 245.90211325374793)\">movie</span> <span style=\"background-color: RGB(193.49482128893277, 255.0, 193.49482128893277)\">is</span> <span style=\"background-color: RGB(156.10073116854127, 255.0, 156.10073116854127)\">awful,</span> <span style=\"background-color: RGB(227.83093353747805, 255.0, 227.83093353747805)\">I</span> <span style=\"background-color: RGB(229.10165420206218, 255.0, 229.10165420206218)\">regret</span> <span style=\"background-color: RGB(144.38771653284508, 255.0, 144.38771653284508)\">seing</span> <span style=\"background-color: RGB(224.26322615279904, 255.0, 224.26322615279904)\">it,</span> <span style=\"background-color: RGB(200.66887131077607, 255.0, 200.66887131077607)\">it</span> <span style=\"background-color: RGB(184.2894079849247, 255.0, 184.2894079849247)\">is</span> <span style=\"background-color: RGB(215.67795716521888, 255.0, 215.67795716521888)\">a</span> <span style=\"background-color: RGB(0.0, 255.0, 0.0)\">bad</span> <span style=\"background-color: RGB(172.44853814223757, 255.0, 172.44853814223757)\">movie.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lime(example, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-provider",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://arxiv.org/pdf/1602.04938.pdf\n",
    "- https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "- https://vanderbei.princeton.edu/tex/talks/MOPTA14/L1_reg.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
